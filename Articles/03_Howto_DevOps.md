# Как стать DevOps инженером за полгода или даже быстрее. Часть 1. Введение

https://habr.com/ru/companies/ua-hosting/articles/500996/

[Автор оригинала: Игорь Кантор (Igor Kantor)](https://medium.com/@devfire/how-to-become-a-devops-engineer-in-six-months-or-less-366097df7737)

## Содержание

+ [Часть 1. Введение](#часть-1-введение)
+ [Часть 2. Конфигурирование](#часть-2-конфигурирование)
+ [Часть 3. Версии](#часть-3-версии)
+ [Часть 4. Пакетирование программ](#часть-4-пакетирование-программ)
+ []()

# Часть 1. Введение

## Целевая аудитория

Вы разработчик, который хочет повернуть свою карьеру в сторону более совершенной модели DevOps? Вы являетесь классическим Ops-инженером и хотели бы получить представление о том, что означит DevOps? Или же вы не являетесь ни тем, ни другим и, потратив некоторое время на работу в области ИТ-технологий, хотите поменять работу и понятия не имеете, с чего начать?
Если да, то читайте дальше, чтобы узнать, как можно стать инженером DevOps среднего уровня за шесть месяцев! Наконец, если вы уже много лет занимаетесь DevOps, то все равно сможете почерпнуть много полезного из этого цикла статей и узнать, где находится отрасль интеграции и автоматизации в данный момент и куда она стремится в своем развитии.

![03](/Articles/img/03_01.jpeg)

<hr>

[Содержание](#содержание)

## Что это вообще такое?

Во-первых, что такое DevOps? Вы можете погуглить определения и пробраться через всю эту словесную шелуху, но знайте, что большинство из определений просто мешанина слов, облеченная в обтекаемую форму. Поэтому я приведу вам выжимку из всех этих определений: DevOps — это такой способ поставки программного обеспечения, при котором головная боль и ответственность делится между всеми причастными. Вот и все.

Хорошо, но что же все-таки означает это сокращение? Оно означает, что традиционно разработчики Developers (люди, создающие программное обеспечение) в своей работе руководствовались стимулами, которые значительно отличались от стимулов Operations (операционистов, или людей, которые управляют программным обеспечением). Например, как разработчик, я хочу как можно быстрее создать как можно больше новых функций. В конце концов, это моя работа, и именно этого требуют клиенты! Однако, если я человек Ops, то мне нужно как можно меньше новых функций, потому что каждая новая функция — это изменение, а любое изменение чревато неполадками. В результате такого рассогласования стимулов и родился DevOps.

DevOps пытается объединить разработку и операции (интеграцию и автоматизацию) в одну группу. Идея заключается в том, что теперь одна группа будет разделять как боль, так и ответственность (и, вероятно, вознаграждение) за создание, развертывание и получение дохода от программного обеспечения, ориентированного на клиента.

Пуристы скажут вам, что нет такой вещи, как ”инженер DevOps". «DevOps — это культура, а не роль”, — скажут они вам. Конечно, с технической точки зрения они правы, но, как это часто бывает, этот термин вышел за пределы своего первоначального значения. Так вот, инженер DevOps – это что-то вроде “системного инженера 2.0». Другими словами, это тот, кто понимает жизненный цикл разработки программного обеспечения и создает инструменты и процессы разработки программного обеспечения для решения классических операционных задач.

![03](/Articles/img/03_02.jpeg)

DevOps в конечном счете означает создание цифровых конвейеров, которые берут код с ноутбука разработчика и превращают его в доход от использования конечного продукта, вот в чем все дело. Обратите внимание на то, что выбор карьеры DevOps достаточно высоко компенсируется финансовым вознаграждением, причем почти каждая компания либо “делает DevOps”, либо претендует на это. Независимо от того, где находятся эти компании, общие возможности трудоустройства в качестве DevOps довольно высоки и подразумевают «веселую» и значимую занятость на долгие годы вперед.

Однако будьте осторожны с компаниями, нанимающими “команду DevOps " или «отдел DevOps». Строго говоря, такие вещи не должны существовать, потому что в конечном счете DevOps — это все же культура и способ доставки программного обеспечения, а не укомплектование новой команды или создание отдела с модным названием.

## Отказ от ответственности

А теперь давайте на минутку отставим в сторону стакан «Кул-Эйда» и подумаем о следующем. Вы слышали старую пословицу «младших инженеров DevOps не бывает?”. Если нет, то знайте, что это популярный троп на Reddit и StackOverflow. Но что он значит?

По-простому эта фраза означает, что требуется много лет опыта в сочетании с твердым пониманием инструментов, чтобы в конечном итоге стать действительно эффективным практиком Senior DevOps. И, к сожалению, здесь нет кратчайшего пути для достижения цели. Таким образом, это не попытка обмануть систему — я не думаю, что на самом деле можно притвориться старшим инженером DevOps с несколькими месяцами опыта в этой отрасли. Достижение четкого понимания быстро меняющихся инструментов и методологий требует многолетнего опыта, и от этого никуда не деться. Однако существует почти согласованное (модное, если хотите) меню инструментов и концепций, которые используют большинство компаний, и именно об этом пойдет речь.

Опять же, инструменты отличаются от навыков, поэтому, пока вы изучаете инструменты, убедитесь, что вы не пренебрегаете своими навыками (опросы, создание сетей, письменное общение, устранение неполадок и т. д.). Главное, не упускайте из виду то, что мы хотим найти – способ создания полностью автоматизированного цифрового конвейера, который берет идеи и превращает их в приносящие доход фрагменты кода. Это единственный и самый важный вывод из всей этой статьи!

## Хватит болтовни, когда я смогу начать?

Ниже приведена дорожная карта «Фундаментальные знания DevOps». Освоив все, что там изображено, можете смело и честно называть себя инженером DevOps! Или облачным инженером, если вам не нравится название “DevOps”.

![03](/Articles/img/03_03.jpeg)

Эта карта отображает мое (и, вероятно, большинства людей, работающих в этом пространстве) представление о том, что должен знать компетентный инженер DevOps. Тем не менее, это только мнение, и, конечно, будут несогласные с ним. Это нормально! Мы здесь не стремимся к совершенству, мы стремимся к прочному фундаменту, на котором реально можно строить.

Вы должны пройти этот путь постепенно, слой за слоем. Начать (и продолжать!) следует с фундаментальных основ, изучив сначала элементы, обозначенные синим цветом — Linux, Python и AWS. Затем, если позволит время или спрос на рынке труда, займитесь фиолетовыми вещами — Golang и Google Cloud.

Честно говоря, основополагающий верхний слой — это то, что вам придется изучать бесконечно. OS Linux очень сложна, и на ее освоение уходят годы. Python требует постоянной практики, чтобы оставаться в курсе событий. AWS развивается так быстро, что то, что вы знаете сегодня, через год составит лишь часть общего портфеля знаний. Как только изучите основы, переходите к реальному набору навыков. Обратите внимание, что всего существует 6 синих колонок (Конфигурирование, Версия, Пакетирование, Развертывание, Запуск, Мониторинг), по одной на месяц изучения.

![03](/Articles/img/03_04.jpeg)

Вы, конечно, заметили отсутствие в нашем шестимесячном конвейере важного этапа – тестирования. Я намеренно не включил его в дорожную карту, потому что написание модуля, интеграция и приемо-сдаточные тесты даются нелегко и традиционно ложатся на плечи разработчиков. И пропуск этапа «тестирование» объясняется тем, что цель этой дорожной карты как можно быстрее освоить базовые навыки и инструменты. Отсутствие опыта тестирования, по мнению автора, является лишь незначительным препятствием для правильного использования DevOps.

Кроме того, помните, что мы не изучаем здесь целую кучу несвязанного технического лепета, а стремимся к пониманию инструментов, которые в единой связке создают понятную историю. Эта история представляет собой сквозную автоматизацию процесса — цифровой конвейер, который перемещает биты подобно сборочной линии. Вы же не хотите изучать кучу инструментов и постоянно останавливаться! Инструментарий DevOps меняется быстро, а концепции — гораздо реже. Поэтому вы должны стремиться к использованию инструментов в качестве обучающих прокси для концепций более высокого уровня.

Ладно, давайте копнем немного глубже!

## Фундаментальные знания

Под верхней ступенькой с надписью Foundation вы видите навыки, которыми должен овладеть каждый инженер DevOps. Эти навыки – уверенное обращение с тремя «столпами» отрасли, коими являются: операционная система, язык программирования и публичное облако. Эти вещи не являются тем, с чем можно по-быстрому ознакомиться и пойти дальше. Эти навыки нужно постоянно совершенствовать и оттачивать мастерство обращения с ними, чтобы находится в авангарде отрасли и актуализировать окружающую вас профессиональную среду. Давайте пройдемся по ним по очереди.

Linux это то, где все работает. Можете ли вы быть потрясающим практиком DevOps, полностью оставаясь в рамках экосистемы Microsoft? Конечно, можете! Нет такого закона, который предписывал бы использовать только Linux. Однако учтите – не смотря на то, что все вещи Linux можно проделать и в Windows, там это происходит гораздо болезненней и с меньшими функциональными возможностями. На данный момент можно смело предположить, что без знания Linux невозможно стать настоящим профессионалом DevOps, поэтому Linux это то, что вы должны изучать и изучать.

Честно говоря, лучший способ сделать это — просто установить Linux (Fedora или Ubuntu) дома и пользоваться им как можно больше. Конечно, вы переломаете кучу вещей, будете застревать в рабочих процессах, вам придется все исправлять, зато вы узнаете Linux!

![03](/Articles/img/03_05.jpeg)

Кстати, в Северной Америке более распространены варианты RedHat, поэтому имеет смысл начать с Fedora или CentOS. Если вы задаетесь вопросом, следует ли вам приобрести KDE или Gnome edition, выберите KDE. Это то, чем пользуется сам Линус Торвальдс.

Python в наши дни является доминирующим бэк-энд языком. С ним легко начать работу, он широко используется. Python очень распространен в сфере искусственного интеллекта и машинного обучения, поэтому, если вы когда-нибудь захотите перейти в еще одну горячую сферу деятельности, то будете полностью к этому готовы.

![03](/Articles/img/03_06.jpeg)

Amazon Web Services: опять же, невозможно стать опытным профессионалом DevOps без твердого понимания того, как работает публичное облако. И если вы хотите узнать об этом как можно больше, изучите Amazon Web Services. Это ведущий игрок в данной области услуг, который предлагает самый богатый набор рабочих инструментов.

Можно ли вместо этого начать с Google Cloud или Azure? Конечно, можно! Но помня последний финансовый кризис, следует учесть, что AWS — это самый безопасный вариант, по крайней мере, в 2018 году, так как позволяет бесплатно зарегистрировать аккаунт и приступить к изучению возможностей облачных сервисов. Кроме того, AWS console предоставляет пользователю простое и понятное меню для выбора. Хорошая новость заключается в том, что для этого вам не нужно знать все технологии Amazon.

![03](/Articles/img/03_07.jpeg)

Начните со следующего: VPC, EC2, IAM, S3, CloudWatch, ELB (Elastic Load Balancing под прикрытием EC2) и Security Group. Этих вещей достаточно, чтобы начать работу, и каждое современное, облачное предприятие достаточно активно использует эти инструменты. Собственный учебный сайт AWS — хорошее место для начала работы.

Я рекомендую вам ежедневно уделять 20-30 минут изучению и практике с языком Python, операционной системой Linux и облачным сервисом AWS в дополнение к другим вещам, которые вам придется изучить. В целом, я считаю, что тратить по часу в день пять раз в неделю достаточно, чтобы понять происходящие в отрасли DevOps процессы в течение 6 месяцев или даже меньше. Существует в общей сложности 6 основных составляющих, каждая из которых соответствует месяцу обучения. Это все, что вам понадобится для приобретения базовых знаний.
В последующих статьях мы рассмотрим следующий уровень сложности: как полностью автоматизировать настройку, версию, пакетирование, развертывание, запуск и мониторинг программного обеспечения.

<hr>

[Содержание](#содержание)

# Часть 2. Конфигурирование

## Освежим память по-быстрому

В первой части я утверждал, что работа инженера DevOps заключается в создании полностью автоматизированных цифровых конвейеров, которые перемещают код от машины разработчика к производству. Для эффективного выполнения этой работы требуется понимание основ, которыми являются ОС, язык программирования и облачный сервис хранения данных, а также хорошее понимание базирующихся на этой основе инструментов и навыков.

Напомню, что ваша цель состоит в том, чтобы сначала слева направо изучить вещи синего цвета, а затем также слева направо изучить вещи фиолетового цвета. Сейчас мы рассмотрим первый из 6 месяцев обучения, посвященный конфигурированию.

![03](/Articles/img/03_08.jpeg)

Что же происходит на этапе конфигурирования? Поскольку код, который мы создаем, нуждается в машинах для запуска, этап конфигурирования фактически создает инфраструктуру, которая и выполняет наш код.

В прошлом создание инфраструктуры обеспечения было длительным, трудоемким и подверженным ошибкам испытанием. Теперь, поскольку у нас есть наше потрясающее облако, вся подготовка может быть выполнена одним нажатием кнопки. Или, по крайней мере, несколькими нажатиями. Однако оказывается, что нажимать кнопки для выполнения этих задач — плохая идея, потому что это означает:
+ склонность к ошибкам (а люди совершают ошибки);
+ игнорирование версий (нажатия кнопок не могут храниться в Git-репозитории);
+ невоспроизводимость и неповторяемость (больше машин = больше кликов);
+ невозможность проверки на лету (я без понятия, будут ли мои клики действительно работать или наоборот все испортят).

![03](/Articles/img/03_09.jpeg)

Например, подумайте обо всей работе, необходимой для
+ обеспечения вашей среды разработки…
+ затем среды int…
+ затем QA…
+ затем staging…
+ затем prod в США…
+ затем prod в ЕС…,<br>
это очень быстро станет довольно утомительным и раздражающим. 

Поэтому вместо механических кликов кнопкой мыши используется новый способ под названием «infrastructure-as-code», и именно об этом пойдет речь на данном этапе конфигурирования вашей системы. «Инфраструктура как код» означает конфигурирование системы с помощью файлов конфигурации, а не через ручное редактирование конфигураций на серверах или интерактивное взаимодействие. Данный способ может представлять собой как декларативное, так и скриптовое описание инфраструктуры. В соответствии с передовой практикой DevOps, «infrastructure-as-code» требует, чтобы любая работа, необходимая для предоставления вычислительных ресурсов, выполнялась только с помощью кода. Под «вычислительными ресурсами» я подразумеваю все необходимое для правильного запуска приложения в prod: собственное вычислительные ресурсы, хранилище, сеть, базы данных и т. д. Отсюда и название — «инфраструктура как код”.

Кроме того, это означает, что вместо того, чтобы «прощелкать» наш путь через механическое развертывание инфраструктуры, мы будем:

+ описывать желаемое состояние инфраструктуры в Terraform;
+ хранить его в нашей системе управления версиями Source Code Control;
+ проходить через формальный процесс Pull Request, чтобы получать обратную связь;
+ тестировать работоспособность;
+ выполнять конфигурирование с целью обеспечить работу системы всеми необходимыми ресурсами.

## Почему это, а не то?

Очевидный вопрос: „Почему именно Terraform? Почему не Chef, Puppet, Ansible, CFEngine, Salt или CloudFormation?”. Хороший вопрос! При его обсуждении были пролиты целые бочки виртуальных чернил. Я думаю, что вы должны изучить Terraform, потому что:

+ это очень модно, поэтому у вас будет куча возможностей для трудоустройства;
+ это легче усваивается;
+ это кроссплатформенный продукт.

Конечно, вы можете выбрать любой другой вариант и тоже добиться успеха. Но я вынужден заметить следующее. Данная отрасль быстро и достаточно хаотично развивается, но я вижу такое развитие событий: традиционно такие вещи, как Terraform и CloudFormation использовались для обеспечения инфраструктуры, в то время как Ansible и ему подобные системы использовались для ее настройки.

![03](/Articles/img/03_10.jpeg)

Поэтому вы можете считать Terraform инструментом для создания фундамента, а Ansible – подъемным краном для возведения дома на этом фундаменте, с последующим развертыванием приложения в качестве крыши (развертывание тоже возможно осуществить с помощью Ansible).
Другими словами, вы создаете свои виртуальные машины с помощью Terraform, а затем используете Ansible для настройки серверов, а также развертывания своих приложений. Традиционно эти вещи используются именно таким образом.

Однако Ansible может сделать многое из того (если не все), что может сделать Terraform, но верно и обратное утверждение. Пусть это вас не беспокоит. Просто знайте, что Terraform является одним из лидирующих инструментов отрасли «infrastructure-as-code», поэтому я настоятельно рекомендую вам начать именно с него.

![03](/Articles/img/03_11.jpeg)

На самом деле, опыт работы со связкой Terraform+AWS является одним из самых востребованных навыков DevOps – инженера. Но даже если вы собираетесь пожертвовать Ansible в пользу Terraform, вам все равно нужно знать, как программно настроить большое количество серверов, не так ли? Оказывается, что это вовсе не обязательно!

## Неизменяемое развертывание

Я предсказываю, что инструменты управления конфигурацией, такие как Ansible, будут терять свою важность, в то время как инструменты подготовки инфраструктуры, такие как Terraform или CloudFormation, будут ее наращивать. И все это из-за того, что называется “неизменяемым развертыванием“. Проще говоря, это означает практику никогда не изменять развернутую инфраструктуру, то есть ваша единица развертывания — это виртуальная машина или контейнер Docker, а не фрагмент кода.

При этом вы не развертываете код на набор статических виртуальных машин, а развертываете целые виртуальные машины вместе с «запеченным» в них кодом. Вы не меняете способ настройки виртуальных машин, а на месте развертываете новые виртуальные машины с нужной конфигурацией. Вы не исправляете машины prod, вы развертываете новые, уже исправленные машины.

Вы не запускаете один набор виртуальных машин в dev, а другой набор машин в prod, они все одинаковы. На самом деле вы можете совершенно безопасно отключить весь SSH- доступ ко всем машинам prod, потому что там нечего делать -нет настроек для изменения, нет журналов для просмотра (подробнее я расскажу о журналах позже). При правильном использовании это очень мощный шаблон, который я настоятельно рекомендую использовать!

Неизменяемые развертывания требуют, чтобы конфигурация была отделена от вашего кода. Пожалуйста, прочитайте манифест [The Twelve-Factor App](https://12factor.net/), который подробно описывает это (и другие удивительные идеи!) в мельчайших подробностях. Это обязательное чтение для практикующих DevOps.

Отсоединение кода от конфигурации очень важно, ведь вы же не хотите повторно развертывать весь стек приложений каждый раз, когда вы «ворошите» пароли своей базы данных. Вместо этого убедитесь, что приложения извлекают его из внешнего хранилища конфигураций (SSM/Consul/etc.). Кроме того, вы легко увидите, как с появлением неизменяемых развертываний такие инструменты, как Ansible, начинают играть менее заметную роль. Причина в том, что вам нужно настроить только один сервер и развернуть его целую кучу раз в составе вашей группы автоматического масштабирования.

Если вы создаете контейнеры, то вам по определению нужны неизменяемые развертывания. Вы же не хотите, чтобы ваш dev-контейнер отличался от контейнера QA, который к тому же будет отличаться от prod-контейнера. Вам нужен совершенно одинаковый контейнер во всех средах, так как это позволяет избежать смещения конфигурации и упрощает откат в случае возникновения проблем.

Помимо контейнеров, для тех людей, которые только начинают свою работу, подготовка инфраструктуры AWS с использованием Terraform представляет собой хорошую учебную модель DevOps и то, что вам действительно нужно освоить.

Но подождите… что делать, если вам нужно посмотреть журналы, чтобы устранить проблему? В этом случае для просмотра журналов не нужно входить в машины, достаточно просмотреть централизованную инфраструктуру ведения журналов для всех ваших логов. Какой-то парень уже опубликовал на данном ресурсе подробную [статью](https://medium.com/@devfire/deploying-the-elk-stack-on-amazon-ecs-dd97d671df06), как развернуть стек ELK в AWS ECS, можете ее прочитать, чтобы узнать, как это делается на практике. Опять же, вы можете полностью отключить удаленный доступ и чувствовать себя намного безопаснее, чем большинство присутствующих там людей.

Подводя итог, можно сказать, что наше полностью автоматизированное путешествие “DevOps» начинается с подготовки вычислительных ресурсов, необходимых для выполнения этапа настройки кода. И лучший способ добиться этого — использовать неизменяемые развертывания. Если вас интересует, с чего следует начинать, возьмите за отправную точку комбинацию Terraform+AWS!

Вот и все, что касается этапа конфигурации, в следующей статье мы рассмотрим второй этап — версии.

<hr>

[Содержание](#содержание)

# Часть 3. Версии

![03](/Articles/img/03_12.jpeg)

## Освежим память

В первой части мы говорили о культуре и целях DevOps, во второй — о том, как заложить основу для будущих развертываний кода с помощью Terraform, который сам является кодом. В третьей части мы обсудим, как уберечь все эти части кода от полного беспорядка. Спойлер: это все из-за Git!

**Бонус**: мы также поговорим о том, как использовать этот самый Git для создания и продвижения вашего собственного личного бренда. На картинке показано, где мы сейчас находимся.

![03](/Articles/img/03_13.jpeg)

## Зачем об этом беспокоиться?

Что имеется в виду под управлением версиями (versioning)? Представьте, что вы работаете над каким-то программным обеспечением и постоянно вносите в него изменения, добавляя или удаляя функции по мере необходимости. Часто последнее изменение будет фундаментальным изменением, ломающим все созданное ранее. Если вы представитель старой школы, то наверняка назовете свой первый файл awesome_code.p1.

Затем вы начинаете вносить изменения, и вам нужно сохранить то, что работает, на случай, если придется к нему вернуться. Поэтому вы переименовываете свой файл на такой: awesome_code.12.25.2018.p1.

Все работает прекрасно до тех пор, когда в один и тот же день вы не сделаете несколько изменений, и вам придется назвать новый файл awesome_code.GOOD.12.25.2018.p1. И продолжаете в том же духе.

Скорее всего, в профессиональной среде у вас есть несколько команд, сотрудничающих в одной и той же кодовой базе, что еще больше нарушает эту модель. Излишне говорить, что этот сумасшедший поезд быстро сходит с рельсов.

## Система управления версиями Source Code Control

![03](/Articles/img/03_14.jpeg)

Используйте систему управления версиями SCC – это способ сохранить ваши файлы в централизованном месте, в котором несколько команд могут совместно работать над общей кодовой базой. Эта идея не нова. Самое раннее упоминание о системе SCC, которое мне удалось найти, относится к 1972 году. Таким образом, идея о том, что мы должны централизовать наш код в одном месте, определенно устарела.

Однако относительно новой является идея о том, что все производимые артефакты должны быть версионными. Это означает, что все, что касается вашей производственной среды, должно храниться в системе управления версиями, подлежать отслеживанию, проверке и фиксации истории изменений.

Более того, применение закона “все артефакты prod должны быть версионными” действительно заставляет вас подходить к проблемам по принципу “автоматизация прежде всего”.

Например, когда вы решаете просто кликнуть по сложной проблеме в своей среде разработки AWS, вы можете сделать паузу и подумать: “является ли это кликом по версионному артефакту”? Конечно, ответ будет “нет".

Хотя делать быстрые прототипы через пользовательский интерфейс, чтобы увидеть, работает что-то или нет, является нормальной практикой, ваш труд будет недолговечным. Поэтому, занимаясь перспективной и длительной по времени работой, убедитесь, что делаете ее в Terraform или другом инструменте типа «инфраструктура-как-код». Запомните — управлять версионными артефактами и хранить их следует при помощи репозитория Git.

## Репозиторий Git

До появления Git использование SCCS, таких как SVN, было неуклюжим, не удобным для пользователя и в целом довольно болезненным опытом. Отличие Git в том, что он обеспечивает распределенное управление версиями. Проще говоря, вы не блокируете других пользователей централизованного хранилища исходного кода, пока работаете над своими изменениями, а работаете с полной копией кодовой базы. После того, как вы закончите свою работу, эта копия будет внедрена в главный репозиторий Master repository.

Имейте в виду, что вышеизложенное является грубым упрощением того, как это работает. Такого описания достаточно для целей данной статьи, однако детальное знание работы Git является трудоемким, но полезным опытом.

![03](/Articles/img/03_15.jpeg)

Пока что просто запомните, что Git работает не так, как SVN. Это распределенная система управления исходным кодом (версиями), в которой несколько команд разработчиков могут безопасно и надежно работать над общей кодовой базой.

## Зачем это нужно знать?

Я решительно утверждаю, что, не зная, как работает Git, вам никогда не стать профессиональным инженером DevOps (Cloud). Как же его изучить? Замечу, что результат поиска в Google по запросу «Учебник Git» обычно выдает ссылки на чрезвычайно раздутые и запутанные пособия. Тем не менее, среди них попадаются несколько действительно толковых учебников.

Одна из таких серий учебников, которые я всем рекомендую прочитать, изучить и использовать на практике, это [Atlassian’s Git Tutorials](https://www.atlassian.com/git/tutorials). Все они достаточно хороши, но один раздел, [Git Workflows](https://www.atlassian.com/git/tutorials/comparing-workflows), описывающий рабочие процессы этого репозитория, используется профессиональными программистами во всем мире.

Еще один действительно хороший учебник — это изучение ветвления репозитория Learn Git Branching. Atlassian tutorials построен по принципу «прочти и выучи», а Learn Git Branching представляет собой интерактивный учебник. В любом случае, вы не продвинетесь далеко в изучении DevOps, если не поймете, как работает этот репозиторий.

![03](/Articles/img/03_16.jpeg)

Замечу, что отсутствие понимания того, как работает функция Git Branching или неспособность объяснить, что такое Gitflow, топит во время собеседования 99% претендентов на кандидатуру инженера-разработчика DevOps. Это ключевой момент — вы можете прийти на собеседование и не знать Terraform или какой-либо другой новейший модный инструмент infrastructure-as-code, и это нормально, потому что вы можете изучить его в процессе работы. Но незнание работы Git свидетельствует о том, что вам не хватает основ современных передовых практик разработки программного обеспечения, не важно, касается ли это DevOps или нет. Это сигнализирует менеджерам по найму, что ваша кривая обучения слишком неровная.

И наоборот, ваша способность уверенно говорить о лучших практиках Git говорит менеджерам по найму, что вы пришли с установкой в первую очередь заняться разработкой программного обеспечения, и это именно тот образ, который вы хотите спроецировать. 

Вывод: вам не нужно становиться ведущим мировым экспертом по Git, чтобы получить эту потрясающую вакансию DevOps, но вам необходимо некоторое время жить и дышать Git, чтобы уверенно говорить о том, что с ним происходит. Для этого, как минимум, вы должны хорошо разбираться в том, как сделать следующее:

+ создать копию репозитория (Fork a repo);
+ cоздать ветвление Git;
+ синхронизировать поток к репозиторию и обратно;
+ создать запрос Pull Request.

## Что дальше?

Как только вы изучите вводные уроки в Git, заведите себе учетную запись на GitHub. Это самый распространенный репозиторий Git с открытым исходным кодом, и вы наверняка захотите быть вместе с остальными адептами Git.

Как только у вас будет свой аккаунт на GitHub, начните заносить в него свой код. Все, что требует от вас написания кода в процессе работы, регулярно фиксируйте на GitHub. Это не только прививает хорошую дисциплину обращения с версиями, но и помогает вам создать свой собственный бренд.

Примечание: при изучении использования git+GitHub обратите особое внимание на Pull Request (или PRs, если вы хотите быть крутым).

## Бренд

Кстати о крутизне: собственный бренд — это способ продемонстрировать всему миру, на что вы способны. Один из способов (в настоящее время это один из лучших способов!) заключается в том, чтобы прочно привязать GitHub в качестве прокси для вашего бренда. Почти все работодатели в наши дни так или иначе попросят об этом. Поэтому вы должны стремиться иметь аккуратный, тщательно курируемый аккаунт на GitHub. Это то, что вы можете поместить в свое резюме и чем можете гордиться.

![03](/Articles/img/03_17.jpeg)

В следующих статьях я расскажу, как создать простой, но классный сайт на GitHub с использованием генератора статических сайтов Hugo. Он написан на Go, и, пожалуй, на сегодня является самым быстрым среди аналогов. Hugo собирает около 5000 страниц за 6 секунд, что в 75 раз больше скорости Middleman. Но вам пока что достаточно просто поместить свой код в GitHub.
Позже, когда вы наберетесь опыта, стоит подумать о том, чтобы иметь две учетные записи GitHub. Одну для хранения собственноручно написанного прикладного, рабочего кода, а другую — для хранения кода, который вы хотите показать другим.

Итак, просуммируем вышесказанное:

+ изучайте Git;
+ размещайте на GitHub все, чему вы научились;
+ задействуйте два аккаунта для хранения и демонстрации всего, чему вы научились
+ получите от этого выгоду!

**Выводы**

Будьте в курсе последних разработок в этой области, таких, как GitOps. GitOps выводит все идеи, которые мы обсуждали до сих пор, на новый уровень, где все делается с помощью git, pull-запросов и конвейеров развертывания.

Обратите внимание, что GitOps и подобные им разработки говорят о деловой стороне вещей, то есть указывают на то, что вы не просто используете Git, потому что это круто и модно. Вы используете его для обеспечения гибкости бизнеса, ускорения инноваций и более быстрого предоставления функций, то есть для того, чтобы в конечном итоге зарабатывать больше денег!

<hr>

[Содержание](#содержание)

# Часть 4. Пакетирование программ

![03](/Articles/img/03_18.jpeg)

Рассмотрим, как упаковать ваш код для легкого развертывания и последующего выполнения. Напомню, что сейчас мы находимся здесь:

![03](/Articles/img/03_19.jpeg)

Независимо от того, разговариваете ли вы со своими нынешними или будущими работодателями, вы должны быть в состоянии четко сформулировать, что такое DevOps и почему это важно.

Изложите последовательную историю о том, как лучше всего быстро и эффективно доставить код с ноутбука разработчика до места развертывания конечного продукта с извлечением соответствующей прибыли. Мы изучаем не кучу разрозненных, модных инструментов DevOps, а набор навыков, руководствуясь потребностями бизнеса и опираясь на технические инструменты. Помните, что изучение каждого этапа DevOps занимает примерно месяц обучения, что в общей сложности займет у вас шесть месяцев.

## Учебник по виртуализации

Помните физические серверы? Те самые серверы, для которых вы неделями ждали одобрения заказа на поставку, согласования процесса отправки, одобрения дата-центром, подключения к сети, установки ОС и патчей? Такими серверы пришли в нашу жизнь.

Представьте себе, что единственный способ обрести жилище — это построить совершенно новый дом. Вам ведь нужно где-то жить? Вот и ждите, пока его построят, сколько бы времени это ни заняло! Вроде бы круто, потому что каждый получает собственный дом, но обременительно, потому что его строительство занимает много времени. Следуя этой аналогии, физический сервер подобен дому.

Со временем этот процесс стал раздражать, и действительно умные люди придумали идею виртуализации. Они решили запустить кучу воображаемых машин на одной физической машине и заставили каждую из них притворяться настоящей машиной. Гениально!

Поэтому, если вам действительно нужен дом, вы можете построить свой собственный и подождать шесть недель. Или же вы можете заселиться в многоквартирный дом и делиться ресурсами с другими жильцами. Может быть, не так круто, но достаточно хорошо! И самое главное, вам не нужно ничего ждать!

Так продолжалось некоторое время, и такие компании, как VMWare, наварили на этом серьезный капитал. Затем другие умные люди решили, что запихивать кучу виртуальных машин в физическую машину недостаточно: нужна более компактная упаковка большего количества процессов в меньшее количество ресурсов.

Итак, дом или даже квартира обходится слишком дорого, так может попробовать просто временно снимать комнату? Причем я могу въезжать и выезжать из нее в любой момент! Вот что по сути представляет собой Docker по состоянию на декабрь 2018 года.

![03](/Articles/img/03_20.jpeg)

## Рождение Docker

**Docker** – это новая технология, базирующаяся на очень старой идее. Операционная система FreeBSD содержала концепцию механизма виртуализации jail, которая восходит к 2000 году! Воистину, все новое — это хорошо забытое старое.

И тогда, и сейчас идея состояла в том, чтобы изолировать отдельные процессы внутри одной и той же операционной системы на основе operating system level virtualization, или «виртуализации на уровне системы». Учтите, это не то же самое, что full virtualization, или «полная виртуализация», которая запускает виртуальные машины бок о бок на одном физическом хосте.

На практике это означает, что рост популярности Docker точно отражает рост микросервисов — подхода к разработке программного обеспечения, при котором программное обеспечение разбивается на множество отдельных компонентов. И все эти компоненты нуждаются в своем доме. Развертывание их по отдельности, как автономных Java-приложений или двоичных исполняемых файлов — это огромная боль: то, как вы управляете Java-приложением, отличается от того, как вы управляете приложением C++, и это, в свою очередь, отличается от управления приложением Golang.

Вместо этого Docker предоставляет единый интерфейс управления, который позволяет программистам упаковывать, последовательно развертывать и запускать различные приложения. Это огромная победа, но давайте поговорим о плюсах и минусах Docker.

## Преимущества Docker

### 1. Изоляция процессов

Докер позволяет каждой службе иметь полностью изолировать процесс. Служба А живет в своем собственном маленьком контейнере, со всеми своими зависимостями, служба B тоже живет в своем личном контейнере со всеми своими зависимостями, и эти две службы не конфликтуют.

Более того, если один контейнер выходит из строя, то пострадает только этот контейнер.

Остальные контейнеры будут и должны продолжать работать. Такой механизм идет на пользу безопасности. Если контейнер скомпрометирован, то будет очень трудно (но не невозможно!) выйти из него, чтобы взломать базовую ОС.

Наконец, если контейнер ведет себя неправильно (потребляет слишком много ресурсов процессора или памяти), можно уменьшить «радиус взрыва» только для этого контейнера, не затрагивая остальную часть системы.

### 2. Развертывание

Подумайте о том, как различные приложения строятся на практике. Если это приложение Python, то у него будет множество различных пакетов Python. Некоторые из них будут установлены в виде модулей pip, другие — в виде пакетов rpm или deb, а третьи — в виде простых установок git-clone. Или, если это сделано с virtualenv, то это будет один zip-файл всех зависимостей в каталоге virtualenv.

С другой стороны, если это приложение Java, то у него будет сборка Gradle Built, со всеми ее зависимостями, вытянутыми и разбросанными в соответствующих местах.

Понимаете, в чем дело? Различные приложения, сборки с разными языками и разным временем выполнения создают проблему, когда речь заходит о развертывании этих приложений для prod. Кроме того, проблема усугубляется, если возникают конфликты. Что делать, если служба A зависит от библиотеки Python v1, а служба B — от библиотеки Python v2? Здесь возникает конфликт, поскольку v1 и v2 не могут сосуществовать на одной и той же машине.

И тут в игру вступает Docker. Он позволяет полностью изолировать не только процесс, но и зависимости. Вполне возможно иметь несколько контейнеров, работающих бок о бок, на одной и той же ОС, каждый из которых содержит свои собственные, не совместимые с другими, библиотеки и пакеты.

### 3. Управление выполнением программ

Замечу, что то, как мы управляем разрозненными приложениями, зависит от самого приложения. Код Java прописывается в реестре по-другому, запускается по-другому и отслеживается по-другому, чем код Python. А Python отличается от Golang и т. д.

С помощью Docker мы получаем единый, унифицированный интерфейс управления, который позволяет нам запускать, контролировать, централизовать логи, останавливать и перезапускать множество различных видов приложений. Это огромный выигрыш в производительности, который значительно снижает эксплуатационные издержки работающих производственных систем.

С декабря 2018 года вам больше не придется делать выбор между быстрым запуском Docker и безопасностью виртуальных машин. Проект легковесной платформы виртуализации [Fireckracker](https://thenewstack.io/how-firecracker-is-going-to-set-modern-infrastructure-on-fire/), представленный Amazon, попытался объединить лучшее из обоих решений. Тем не менее, это новая технология, которая только приближается к этапу prod.

![03](/Articles/img/03_21.jpeg)

Примечание: Платформа Firecracker предоставляет средства для создания и управления изолированными окружениями и сервисами, построенными с использованием бессерверной модели разработки. Код проекта написан на языке Rust и [распространяется](https://github.com/firecracker-microvm/firecracker/) под лицензией Apache 2.0.

Firecracker предлагает легковесные виртуальные машины, именуемые microVM. Для их полноценной изоляции применяются технологии аппаратной виртуализации, но при этом обеспечивается производительность и гибкость на уровне обычных контейнеров. Основу платформы составляет монитор виртуальных машин (VMM), использующий встроенный в ядро Linux гипервизор KVM. VMM основан на наработках написанного на языке Rust проекта [crosvm](https://chromium.googlesource.com/chromiumos/platform/crosvm/), который компания Google развивает с целью запуска Linux в ChromеOS. По состоянию на конец 2018 года кодовые базы crosvm и Firecracker разделились, но Amazon планирует передавать в upstream исправления, вносимые в заимствованные компоненты.

Однако, как бы ни был хорош Docker, у него есть и недостатки.

## Введение в Lambda

Во-первых, запущенный Docker все еще продолжает работать на серверах, которые должны быть подготовлены, пропатчены и т.д. Во-вторых, Docker не является 100% безопасным. По крайней мере, он не настолько безопасен, как виртуальная машина. Существует причина, по которой огромные компании, работающие с размещенными контейнерами, делают это внутри виртуальных машин, а не на «голом железе». Им нужны быстрые сроки запуска контейнеров и безопасность виртуальных машин!

![03](/Articles/img/03_22.jpeg)

В-третьих, никто на самом деле не управляет «Докером» как таковым. Вместо этого он почти всегда развертывается как часть сложной структуры оркестровки контейнеров, такой как Kubernetes, ECS, docker-swarm или Nomad. Это довольно сложные платформы, которые требуют специального персонала для работы (подробнее об этих решениях я расскажу позже).

Однако, если я всего лишь разработчик, то просто хочу написать код и попросить кого-то запустить его для меня. Docker, Kubernetes и прочий джаз — неужели я обязан все это изучить? Скажу так: все зависит от обстоятельств. Для людей, которые просто хотят, чтобы кто-то другой запускал их код, облачное хранилище данных AWS Lambda и подобные ему штуки отличный вариант.

AWS Lambda позволяет запускать код без подготовки и управления серверами. Вы платите только за потребляемое вами вычислительное время, и когда ваш код не работает, плата не взимается.
Если вы слышали о бессерверном хранилище, то это оно и есть. Больше никаких серверов для запуска или контейнеров для управления! Просто напишите свой код, упакуйте его в zip-файл, загрузите на Amazon, и пусть они разбираются с вашей головной болью! Кроме того, поскольку «лямбды» недолговечны, взламывать их нечего — «лямбды» довольно безопасны по своей конструкции. Правда, здорово?

Но есть и негативные моменты. Во-первых, «лямбды» могут работать только в течение максимум 15 минут (по состоянию на ноябрь 2018 года). Это означает, что длительно работающие процессы, такие как Kafka или приложения для взлома чисел, не могут работать в Lambda.

Во-вторых, «лямбды» представляют собой Functions-as-a-Service (функции как услуга). Это означает, что ваше приложение должно быть полностью разложено на микросервисы и синхронизировано с другими сложными сервисами PaaS, такими как [AWS Step Functions](https://aws.amazon.com/step-functions/). Однако не каждое предприятие находится на таком уровне архитектуры микросервисов.

В-третьих, устранение неисправностей «лямбд» очень сложно. Они являются облачными средами выполнения, и все исправления ошибок происходят в экосистеме Amazon. Это часто бывает довольно сложным и неинтуитивным. Короче говоря, здесь нет никакого бесплатного обеда.

Замечу, что на конец 2018 года существуют также бессерверные облачные контейнерные решения, такие как [AWS Fargate](https://aws.amazon.com/fargate/). Его механика во многом схожа с Lambda. Если вы только начинаете изучать эти сервисы, настоятельно рекомендую попробовать Fargate, это невероятно простой способ заставить контейнеры работать «правильно». К тому же 13.01.2019 облачные сервисы AWS объявили о значительном снижении цены на Fargate, делает его очень привлекательным выбором для запуска бессерверных контейнеров.

![03](/Articles/img/03_23.jpeg)

**Резюме**

Docker и Lambda — два наиболее популярных современных облачных подхода к упаковке, запуску и управлению приложениями. Они часто являются бесплатными, причем оба подходит для различных случаев использования и приложений.

Как бы то ни было, современный инженер DevOps должен хорошо разбираться и в том, и в другом. Поэтому обучение Docker и Lambda — это хорошие краткосрочные и среднесрочные цели.
Замечу, что до сих пор мы имели дело с темами, которые должны знать инженеры DevOps младшего и среднего уровня. В последующих разделах мы начнем обсуждать методы, которые больше подходят для инженеров среднего и старшего уровня DevOps. Как всегда, для обретения знаний не существует легких путей!

Продолжение будет совсем скоро…